{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#MCD43\" data-toc-modified-id=\"MCD43-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>MCD43</a></span></li><li><span><a href=\"#Processing\" data-toc-modified-id=\"Processing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#MCD43A3\" data-toc-modified-id=\"MCD43A3-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>MCD43A3</a></span></li><li><span><a href=\"#Data-prep\" data-toc-modified-id=\"Data-prep-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data prep</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-SRS\" data-toc-modified-id=\"Define-SRS-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Define SRS</a></span></li><li><span><a href=\"#Permute-x-and-y\" data-toc-modified-id=\"Permute-x-and-y-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Permute x and y</a></span></li><li><span><a href=\"#Flatten-and-transform\" data-toc-modified-id=\"Flatten-and-transform-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Flatten and transform</a></span></li><li><span><a href=\"#Reshape\" data-toc-modified-id=\"Reshape-2.2.4\"><span class=\"toc-item-num\">2.2.4&nbsp;&nbsp;</span>Reshape</a></span></li></ul></li><li><span><a href=\"#Check-spatial-references\" data-toc-modified-id=\"Check-spatial-references-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Check spatial references</a></span></li><li><span><a href=\"#MCD43A1\" data-toc-modified-id=\"MCD43A1-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>MCD43A1</a></span><ul class=\"toc-item\"><li><span><a href=\"#Intro\" data-toc-modified-id=\"Intro-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Intro</a></span></li><li><span><a href=\"#Data-prep\" data-toc-modified-id=\"Data-prep-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Data prep</a></span></li><li><span><a href=\"#SZN\" data-toc-modified-id=\"SZN-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>SZN</a></span></li><li><span><a href=\"#Quality-flags\" data-toc-modified-id=\"Quality-flags-2.4.4\"><span class=\"toc-item-num\">2.4.4&nbsp;&nbsp;</span>Quality flags</a></span></li><li><span><a href=\"#Albedo\" data-toc-modified-id=\"Albedo-2.4.5\"><span class=\"toc-item-num\">2.4.5&nbsp;&nbsp;</span>Albedo</a></span></li><li><span><a href=\"#BSA\" data-toc-modified-id=\"BSA-2.4.6\"><span class=\"toc-item-num\">2.4.6&nbsp;&nbsp;</span>BSA</a></span></li></ul></li></ul></li><li><span><a href=\"#scratch\" data-toc-modified-id=\"scratch-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>scratch</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCD43 Albedos for Florida USGS 2018 Evapotranspiration Model Runs\n",
    "This notebook documents the process for calculating the black, white, and blue sky albedos for Shoemaker et al. 2018 (USGS). Take care of imports first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "## plotting only -->>\n",
    "import cartopy.feature as feat\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{\n",
    "    'family': 'normal', \n",
    "    'weight': 'normal', \n",
    "    'size': 16})\n",
    "\n",
    "## processing -->>\n",
    "from pyproj import Proj, transform\n",
    "import xarray as xr     \n",
    "import numpy as np \n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCD43\n",
    "\n",
    "The HDFs for MCD43A1 are unwieldy and we only need six of the ~20 layers so I requested subsets from APPEEARS in netCDF format. Visit [this document](data/RequestMCD43A3.md) for instructions on how to requests identical subsets using the JSON request records included in this repo.\n",
    "\n",
    "I requested both MCD43A1 and MCD43A3 for Florida for 2018 instead of just MCD43A1 for reasons that I'll explain later. Each products has the data for the whole year in a single netCDF:\n",
    "* MCD43A1: [data\\MCD43A1.006_500m_aid0001.nc](data\\MCD43A1.006_500m_aid0001.nc)\n",
    "* MCD43A3: [data\\MCD43A3.006_500m_aid0001.nc](data\\MCD43A3.006_500m_aid0001.nc)\n",
    "\n",
    "## Processing \n",
    "\n",
    "### MCD43A3\n",
    "\n",
    "MCD43A3 has black- and white-sky albedo calculated for local solar noon observations only, so it resembles a piece of our result.\n",
    "\n",
    "Open the dataset for MCD43A3 with `xr.open_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netcdf = \"data/MCD43A3.006_500m_aid0001.nc\"\n",
    "\n",
    "ds = xr.open_dataset(netcdf) # open to xr.Dataset struct\n",
    "ds = ds.rename({\"xdim\": \"x\", \"ydim\": \"y\"}) # rename dims x,y to stndrd\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the data are conveniently organized along three dimensions *time, x, y*.\n",
    "\n",
    "### Data prep\n",
    "Make a few more improvements to the structure of the dataset:\n",
    "* Add two-dimensional arrays (2) of lat and lon values to improve spatial metadata\n",
    "* Assign some additional metadata about the quality flags information to the *Mandatory_Quality* variables\n",
    "* etc.\n",
    "\n",
    "We need latitudes and longitudes to calculate the solar zenith angle, so use `numpy` and `proj` libraries to generate arrays of lat,lon equivalents for the *x, y* coordinates in the dataset. A few steps are required:\n",
    "\n",
    "#### Define SRS\n",
    "Define spatial information for the source x,y arrays and the target lon,lat arrays using `pyproj.Proj`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not aware of any geoscience application where sinusoidal coordinates are reference to an origin other than lat==0, lon==0. So, this piece is unnecessary, but it stays for the sake of provenance.\n",
    "\n",
    "I only used the lambda `getpar` to avoid having too many columns. The mess below is assembling the attributes from `ds.crs` into the proj4 string to be consumed by `pyproj.Proj`. Use the EPSG code for WGS84:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getpar = lambda a: str(ds.crs.attrs[a])\n",
    "\n",
    "inproj = Proj(\" \".join([\n",
    "    \"+proj=sinu\",\n",
    "    \"+lon_0=\"+getpar(\"longitude_of_central_meridian\"),\n",
    "    \"+x_0=\"+getpar(\"false_easting\"),\n",
    "    \"+y_0=\"+getpar(\"false_northing\"),\n",
    "    \"+a=\"+getpar(\"semi_major_axis\"),\n",
    "    \"+b=\"+getpar(\"semi_minor_axis\"),\n",
    "    \"+units=\"+\"meter +no_defs\"]))\n",
    "\n",
    "outproj = Proj(init=\"epsg:4326\")\n",
    "\n",
    "inproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permute x and y\n",
    "After we expand **x** and **y** to two dimensions, we need immediately flatten them so when they're taken together they represent a sequence of latitude longitude pairs that enumerate over all pixels from top-left to bottom-right of the dataset. \n",
    "\n",
    "You can do this with `numpy.meshgrid` then `numpy.array.flatten`. Use `numpy.meshgrid` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(ds.x.data, ds.y.data)\n",
    "\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten and transform\n",
    "Flatten and transform the expanded 2d arrays and pass them as arguments 3 and 4 to `pyproj.transform` to get lon,lat pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon1d, lat1d = transform(\n",
    "    inproj, \n",
    "    outproj, \n",
    "    xx.flatten(), \n",
    "    yy.flatten())\n",
    "\n",
    "print(\"First five (lon,lat) pairs:\"); list(zip(lon1d[:5], lat1d[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape\n",
    "Reshape the new lon,lat arrays to match the original shape of the 2d x (`xx`) and y (`yy`) arrays. The **latitude** and **longitude** variables in the final dataset will be arranged along the **x** and **y** dimensions (both are 1d), so that every sinusoidal pixel is assigned a geographic reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon2d, lat2d = lon1d.reshape(xx.shape), lat1d.reshape(yy.shape)\n",
    "\n",
    "lat2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add them to our dataset add two additional coordinate variables by creating an `xr.DataArray` for each and adding them to the dataset. This gets us closer to full compliance with CF recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords[\"lat\"] = xr.DataArray(\n",
    "    data=lat2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=dict(\n",
    "        standard_name=\"latitude\",\n",
    "        long_name=\"latitude coordinate\",\n",
    "        units=\"degrees_north\"))\n",
    "\n",
    "ds.coords[\"lon\"] = xr.DataArray(\n",
    "    data=lon2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=dict(\n",
    "        standard_name=\"longitude\",\n",
    "        long_name=\"longitude coordinate\",\n",
    "        units=\"degrees_east\"))\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check spatial references\n",
    "\n",
    "It's probably a good idea to do more thorough review to make sure there are no mistakes. You can do a lot of indexing and stats calculation in a single line of code. But break it out into a couple distinct steps:\n",
    "1. select the **black-sky albedo** variable\n",
    "2. plot the first timestep with `cartopy`\n",
    "3. plot the **gridded averages by month**\n",
    "4. plot a single line for the daily time series over all of Florida\n",
    "\n",
    "**Select BSA:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsa = ds[\"Albedo_BSA_nir\"]; bsa    # select the BSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the first timestep:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11, 10))\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.Sinusoidal.MODIS)\n",
    "bsa.isel(time=0).plot.pcolormesh(x=\"x\", y=\"y\", ax=ax, robust=True,)\n",
    "\n",
    "# optional, aesthetics -->>\n",
    "ax.set_yticklabels([]); ax.set_xticklabels([]);\n",
    "ax.add_feature(feat.OCEAN, zorder=0);\n",
    "ax.add_feature(feat.LAND, zorder=0, edgecolor='black');\n",
    "ax.gridlines(color=\"white\", alpha=0.25); #ax.set_global();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot monthly gridded averages:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsamo = bsa.groupby(bsa.time.dt.month).mean(\"time\")\n",
    "bsamo.plot.pcolormesh(\n",
    "    x='x', \n",
    "    y='y', \n",
    "    col='month', \n",
    "    col_wrap=3, \n",
    "    robust=True, \n",
    "    figsize=(16, 18))\n",
    "ax = plt.gca()\n",
    "ax.set_yticklabels([]); ax.set_xticklabels([]);\n",
    "ax.set_ylabel(\"\"); ax.set_xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The daily average of BSA over the state of Florida for 2018:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsa.mean([\"x\",\"y\"]).plot(x=\"time\", figsize=(14, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCD43A1\n",
    "\n",
    "The MODIS BRDF/Albedo/NBAR product (MCD43) is led by [Professor Crystal Schaaf at UMass Boston](https://www.umb.edu/spectralmass/terra_aqua_modis/modis_brdf_albedo_product_mcd43). The albedo [source code](proc/actual_albedo_tool/actual_albedo_tool.tar.gz) maintained by her lab are accessible at her [ftp site](ftp://rsftp.eeos.umb.edu/data01/Website/actual_albedo_tool.tar.gz). The [readme](proc/actual_albedo_tool/albedo/readme) is the source of most of the `block text` in the notebook.\n",
    "\n",
    "\n",
    "\n",
    "#### Intro\n",
    "\n",
    "#### Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_dataset(\"data/MCD43A1.006_500m_aid0001.nc\")\n",
    "ds = ds.rename({\n",
    "    \"Num_Parameters\": \"param\", \n",
    "    \"xdim\": \"x\", \n",
    "    \"ydim\": \"y\"})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the same coordinates as MCD43A3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latatts = dict(\n",
    "    standard_name=\"latitude\",\n",
    "    long_name=\"latitude coordinate\",\n",
    "    units=\"degrees_north\")\n",
    "\n",
    "ds.coords[\"lat\"] = xr.DataArray(\n",
    "    data=lat2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=latatts)\n",
    "\n",
    "lonatts = dict(\n",
    "    standard_name=\"longitude\",\n",
    "    long_name=\"longitude coordinate\",\n",
    "    units=\"degrees_east\")\n",
    "\n",
    "ds.coords[\"lon\"] = xr.DataArray(\n",
    "    data=lon2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=lonatts)\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset for testing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_jan = ds.isel(time=slice(0,30))\n",
    "ds_jan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SZN\n",
    "The only input to black- and white-sky albedos that doesn't come in MCD43A1 is the solar zenith angle (but, you can get it in MCD43A2 if you wish to use local solar noon). \n",
    "\n",
    "*needs explanation...*\n",
    "\n",
    "We have to calculate solar zenith angles for every pixel, for every timestep in the time series (that's a lot, obv). In this next cell, we import `pysolar`, a widely used solar index calculator for Python, and test the `get_altitude` function with the first day in our time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysolar.solar import *\n",
    "\n",
    "# get a datetime object for Jan 1 2018\n",
    "date = datetime.datetime.strptime(\"2018-01-01\", \"%Y-%m-%d\")\n",
    "\n",
    "# set the timezone to UTC\n",
    "date = date.replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "# get the solar zenith angle\n",
    "alt  = get_altitude(42.206, -71.382, date)\n",
    "\n",
    "alt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the same function with the datetime for timestep 1 and make sure it matches the angle given above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get timestep 1 as a datetime object\n",
    "timestep1 = ds_jan.time[0].data.item()._to_real_datetime()\n",
    "\n",
    "# set timezone to utc\n",
    "timestep1 = timestep1.replace(tzinfo=datetime.timezone.utc)\n",
    "\n",
    "# get solar zenith angle\n",
    "alt2 = get_altitude(42.206, -71.382, timestep1)\n",
    "\n",
    "# check if they are equal\n",
    "alt==alt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True, success! \n",
    "\n",
    "This amounts to 758,280,200 individual calculations (`pixels*timesteps`); it may take 10 minutes or so on a typical workstation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sza_eval(lat, lon, time):\n",
    "    \"\"\"Convert CF to Python datetime.\"\"\"\n",
    "    ts = time.data.item()._to_real_datetime()\n",
    "    ts = ts.replace(tzinfo=datetime.timezone.utc)\n",
    "    return(get_altitude(lat, lon, ts))\n",
    "    \n",
    "# evaluate sza over all arrays using list comprehension \n",
    "sza_arr = np.dstack([sza_eval(lat1d, lon1d, t) for t in ds.time])\n",
    "sza_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array dimensions look correct. We need to reshape the large axis to match the shape of the raster like we did with our 1d lat and lon coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sza2d = sza_arr.reshape((1555, 1336, 365))\n",
    "sza2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the solar zenith angle array to our master dataset as a new variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZA = xr.DataArray(  #ds_jan[\"SZA\"] = \n",
    "    data=sza2d, \n",
    "    coords=[ds_jan.y, ds_jan.x, ds_jan.time], # note that we reorder coords in\n",
    "    dims=[\"time\", \"y\", \"x\"],                  # dims argument to match others\n",
    "    attrs=dict(\n",
    "        units=\"degree\",\n",
    "        standard_name=\"solar zenith angle\",\n",
    "        long_name=\"solar zenith angle\"))\n",
    "\n",
    "SZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_jan.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality flags\n",
    "Reference: https://lpdaac.usgs.gov/products/mcd43a1v006/\n",
    "\n",
    "Fortunately, MCD43 quality flags are as simple as they come (for MODIS):\n",
    "```\n",
    "Value \tDescription\n",
    "0 \t    Processed; good quality (full BRDF inversions)\n",
    "1 \t    Processed; see other QA (magnitude BRDF inversions)\n",
    "2 \t    Processed; good quality (full BRDF inversions); Band 6 filled; dead or noisy detectors\n",
    "3 \t    Processed; see other QA (magnitude BRDF inversions); Band 6 filled; dead or noisy detectors\n",
    "255 \tFill Value\n",
    "```\n",
    "\n",
    "We may decide to filter the pixels derived via magnitude BRDF inversions, but for now we will keep all data. They are already weighted to amplify the best observation over a 16 day period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Albedo\n",
    "\n",
    "Now we finally calculate albedos.\n",
    "\n",
    "The black-sky albedo polynomial is presented in a more practical way in the readme than the equation given in the user guide:\n",
    "\n",
    "```shell\n",
    "$ sed -n '31,53p;53q' proc/actual_albedo_tool/albedo/readme\n",
    "\n",
    "    Calculation of WSA and BSA\n",
    "    --------------------------\n",
    "\n",
    "    The program read the BRDF parameters from out1. Black-sky\n",
    "    albedos are calculated according to the following polynomial\n",
    "    albedo representation.\n",
    "    \n",
    "                          K=iso       k=vol           k=geo\n",
    "    G_0k(term 1)           1.0      -0.007574       -1.284909   <- BSA coefficients\n",
    "    G_1k(term SZN^2)       0.0      -0.070987       -0.166314   <- \n",
    "    G_2k(term SZN^3)       0.0       0.307588        0.041840   <- \n",
    "    WSA                    1.0       0.189184       -1.377622   <- WSA coefficients\n",
    "\n",
    "    BSA(SZN,BAND)=\n",
    "        F_iso(BAND)*(G_0iso + G_1iso*SZN^2 + G_2iso*SZN^3) +\n",
    "        F_vol(BAND)*(G_0vol + G_1vol*SZN^2 + G_2vol*SZN^3) +\n",
    "        F_geo(BAND)*(G_0geo + G_1geo*SZN^2 + G_2geo*SNZ^3)\n",
    "\n",
    "    SZN:  solar zenith angle\n",
    "    BAND: band wavelength\n",
    "    OD:   optical depth\n",
    "    AMT:  aerosol model type\n",
    "   \n",
    "```\n",
    "\n",
    "#### BSA\n",
    "\n",
    "Define some functions that do the math above.\n",
    "\n",
    "We also write a simple function to vectorize each calculation over our giant array. It should run significantly faster than a for loop. We can only vectorize over coordinates with matching dimensions, so we will have to loop over the timesteps.\n",
    "\n",
    "```python\n",
    "def vectorized(a, b):\n",
    "    func = lambda x, y: np.sqrt(x ** 2 + y ** 2)\n",
    "    return xr.apply_ufunc(func, a, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = lambda sza:  1.0      +  0.0*sza**2      + 0.0*sza**3      # Isotropic\n",
    "vol = lambda sza: -0.007574 + -0.070987*sza**2 + 0.307588*sza**3 # RossThick\n",
    "geo = lambda sza: -1.284909 + -0.166314*sza**2 + 0.041840*sza**3 # LiSparseR\n",
    "\n",
    "def iso_vectorized(param1, sza):\n",
    "    pfunc = lambda p1, sza: p1*iso(sza)\n",
    "    return(xr.apply_ufunc(pfunc, param1, sza))\n",
    "    \n",
    "# vectorize each function\n",
    "#vol_vectorized = lambda sza: xr.apply_ufunc(vol, sza)\n",
    "#geo_vectorized = lambda sza: xr.apply_ufunc(geo, sza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sza_input = ds_jan[\"SZA\"]\n",
    "nir_input1 = ds_jan[\"BRDF_Albedo_Parameters_nir\"].sel(param=0)\n",
    "\n",
    "iso_nir = iso_vectorized(nir_input1, sza_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sza_input.isel(time=0).plot.pcolormesh(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_input1.isel(time=0).plot.pcolormesh(x='x', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`bsa_vectorized` is the heavy-lifter. We use it to apply the functions (iso, vol, geo) over two billion times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bsa_vectorize(band):\n",
    "    \"\"\"Vectorize albedo polynomials over two 3d arrays.\"\"\"\n",
    "    \n",
    "    p1 = lambda par,sza: par*iso(par, sza)\n",
    "    p2 = lambda par,sza: par*vol(par, sza)\n",
    "    p3 = lambda par,sza: par*geo(par, sza)\n",
    "    \n",
    "    func = lambda p,s : poly(p, s)\n",
    "    \n",
    "    return(xr.apply_ufunc(func, par, sza))\n",
    "\n",
    "bsa_vectorized(iso, par1, ds[\"SZA\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch\n",
    "**Collect some notes and bits of code here**\n",
    "\n",
    "<img src=\"http://docs.pysolar.org/en/latest/_images/reference_frame.png\" alt=\"alt text\" width=\"500px\">    \n",
    "*source: [http://docs.pysolar.org/en/latest/#location-calculation](http://docs.pysolar.org/en/latest/#location-calculation)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "bsa.plot.pcolormesh(\n",
    "    x='x', \n",
    "    y='y', \n",
    "    col='month', \n",
    "    col_wrap=3, \n",
    "    robust=True, \n",
    "    figsize=(16,18),\n",
    "    #transform=ccrs.Sinusoidal(),\n",
    "    #subplot_kws={'projection': ccrs.Sinusoidal(-82, 28)}\n",
    ")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This binary computes black, white, blue sky albedos from input BRDF parameters from MCD43A1 (HDF):\n",
    "* \n",
    "[/code/albedo/actual_albedo_hdf.exe](./code/albedo/actual_albedo_hdf.exe)\n",
    "\n",
    "```shell\n",
    "\n",
    "$ ./code/albedo/actual_albedo_hdf.exe\n",
    "\n",
    "Usage: actual_albedo.exe [-par][-od][-szn][-out]\n",
    "\n",
    "   -par <par_file>      input MCD43A1 (V005 or V006, in HDF format)\n",
    "   -od  <optical_depth> input optical depth (float, range: 0.0-1.0)\n",
    "   -szn <solar_zenith>  input solar zenith angle you want to compute\n",
    "                        (float, range: 0.0-89.0 degrees)\n",
    "   -out <albedo_file>   output file to save actual albedo (in HDF format)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "bsamo.plot.pcolormesh(\n",
    "    'xdim', \n",
    "    'ydim', \n",
    "    col='month', \n",
    "    col_wrap=3, \n",
    "    robust=True, \n",
    "    figsize=(16,18),\n",
    "    #transform=ccrs.Sinusoidal(),\n",
    "    #subplot_kws={'projection': ccrs.Sinusoidal(-82, 28)}\n",
    ")\n",
    "\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes from the R implementation in my other repo**\n",
    "\n",
    "```R\n",
    "#####################################################################################\n",
    "# These functions are called by the loop function in main_albedo.R\n",
    "#\n",
    "#::METHODS::\n",
    "# \n",
    "#   https://modis.ornl.gov/documentation.html\n",
    "#   https://www.umb.edu/spectralmass/terra_aqua_modis/modis_brdf_albedo_product_mcd43\n",
    "#\n",
    "# Black-sky Albedo = \n",
    "#   Parameters_01 + \n",
    "#   Parameters_02 * (-0.007574 + (-0.070987 * szn^2) + (0.307588 * szn^3)) + \n",
    "#   Parameters_03 * (-1.284909 + (-0.166314 * szn^2) + (0.041840 * szn^3))\n",
    "#\n",
    "# White-sky Albedo = \n",
    "#   Parameters_01 + \n",
    "#   Parameters_02 * (0.189184) + \n",
    "#   Parameters_03 * (-1.377622) \n",
    "#\n",
    "# Actual (Blue-sky) Albedo = \n",
    "#   White-sky Albedo * f(optical depth, solar zenith angle, aerosol type, band) + \n",
    "#   Black-sky Albedo * (1 - f(optical depth, solar zenith angle, aerosol type, band)) \n",
    "#\n",
    "#####################################################################################\n",
    "# Albedo calculation constants\n",
    "#####################################################################################\n",
    "\n",
    "## Black sky constants\n",
    "\n",
    "# Isotropic constant\n",
    "g0iso <- 1.0\n",
    "g1iso <- 0.0\n",
    "g2iso <- 0.0\n",
    "\n",
    "# RossThick constant\n",
    "g0vol <- -0.007574\n",
    "g1vol <- -0.070987\n",
    "g2vol <- 0.307588\n",
    "\n",
    "# LiSparseR constant\n",
    "g0geo <- -1.284909\n",
    "g1geo <- -0.166314\n",
    "g2geo <- 0.041840\n",
    "\n",
    "## White sky constants\n",
    "\n",
    "gIso <- 1.0       # Isotropic\n",
    "gVol <- 0.189184  # RossThick\n",
    "gGeo <- -1.377622 # LiSparseR\n",
    "\n",
    "#####################################################################################\n",
    "# Albedo functions\n",
    "#####################################################################################\n",
    "\n",
    "# Convert SZN degrees to radians\n",
    "Deg2Rad = 3.1415926535/180\n",
    "SF = 1 # Scale factor (0.001) already applied to values by ncdf4. Set to 1.\n",
    "\n",
    "# Black-sky albedo formula\n",
    "BlackSA <- function(p1arr, p2arr, p3arr, szn){\n",
    "  sznrad = szn*Deg2Rad\n",
    "  return((p1arr*SF)+(p2arr*SF)*(g0vol+(g1vol*sznrad^2)+(g2vol*sznrad^3))+(p3arr*SF)*(g0geo+(g1geo*sznrad^2)+(g2geo*sznrad^3)))\n",
    "}\n",
    "\n",
    "# White-sky albedo formula\n",
    "WhiteSA <- function(p1arr, p2arr, p3arr){\n",
    "  return((p1arr*SF)*gIso+(p2arr*SF)*gVol+(p3arr*SF)*+gGeo)\n",
    "}\n",
    "\n",
    "# Actual albedo formula\n",
    "ActualSA <- function(WSA, BSA, LUTVal){\n",
    "  return((WSA*LUTVal)+(BSA*(1-LUTVal)))\n",
    "}\n",
    "\n",
    "#####################################################################################\n",
    "# Lookup tables\n",
    "#####################################################################################\n",
    "\n",
    "LUT <- function(band, szn, sod){\n",
    "  if(band == 'vis'){\n",
    "    return(vislut[paste('X', sprintf('%.2f', sod), sep = ''),round(abs(szn), digits = 0)+1])\n",
    "  }\n",
    "  if(band == 'nir'){\n",
    "    return(nirlut[paste('X', sprintf('%.2f', sod), sep = ''),round(abs(szn), digits = 0)+1])\n",
    "  }\n",
    "  if(band == 'shortwave'){\n",
    "    return(swlut[paste('X', sprintf('%.2f', sod), sep = ''),round(abs(szn), digits = 0)+1])\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
