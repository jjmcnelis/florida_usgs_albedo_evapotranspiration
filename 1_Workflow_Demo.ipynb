{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data\" data-toc-modified-id=\"Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data</a></span></li><li><span><a href=\"#Workflow\" data-toc-modified-id=\"Workflow-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Workflow</a></span><ul class=\"toc-item\"><li><span><a href=\"#Coordinates-and-Solar-Zenith-Angles\" data-toc-modified-id=\"Coordinates-and-Solar-Zenith-Angles-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Coordinates and Solar Zenith Angles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-SRS\" data-toc-modified-id=\"Define-SRS-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Define SRS</a></span></li><li><span><a href=\"#Permute-x-and-y\" data-toc-modified-id=\"Permute-x-and-y-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Permute x and y</a></span></li><li><span><a href=\"#Flatten-and-transform\" data-toc-modified-id=\"Flatten-and-transform-2.1.3\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Flatten and transform</a></span></li><li><span><a href=\"#SZN\" data-toc-modified-id=\"SZN-2.1.4\"><span class=\"toc-item-num\">2.1.4&nbsp;&nbsp;</span>SZN</a></span></li></ul></li><li><span><a href=\"#Quality-flags\" data-toc-modified-id=\"Quality-flags-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Quality flags</a></span></li><li><span><a href=\"#Albedo\" data-toc-modified-id=\"Albedo-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Albedo</a></span><ul class=\"toc-item\"><li><span><a href=\"#Black-sky-albedo\" data-toc-modified-id=\"Black-sky-albedo-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Black sky albedo</a></span></li><li><span><a href=\"#White-sky-albedo\" data-toc-modified-id=\"White-sky-albedo-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>White sky albedo</a></span></li><li><span><a href=\"#Blue-sky-albedo\" data-toc-modified-id=\"Blue-sky-albedo-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>Blue sky albedo</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Demo\n",
    "This notebook documents the process for calculating the [black](#Black-sky-albedo), [white](#White-sky-albedo), and [blue](#Blue-sky-albedo) sky albedos from the MCD43A1 BRDF model parameters downloaded through LP DAAC's APPEEARS tool in netCDF format. \n",
    "## Data\n",
    "See the first notebook ([0_Introduction.ipynb](0_Introduction.ipynb)) for details about how to request identical subsets using the JSON request records.\n",
    "## Workflow\n",
    "Import the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing -->>\n",
    "from pyproj import Proj, transform\n",
    "from math import radians, cos\n",
    "from io import StringIO\n",
    "import xarray as xr   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import `matplotlib` for convenient plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **{\n",
    "    'family': 'normal', \n",
    "    'weight': 'normal', \n",
    "    'size': 16})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the netCDF with `xarray` and print the header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = xr.open_dataset(\"data/MCD43A1.006_500m_aid0001.nc\")\n",
    "ds = xr.open_dataset(\"data/MCD43A1.2018.nc\")\n",
    "ds = ds.rename({\n",
    "    \"Num_Parameters\": \"param\", \n",
    "    \"xdim\": \"x\", \n",
    "    \"ydim\": \"y\"})\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll test the code on a subset of the dataset. Select only the month of January:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.isel(time=slice(0,31))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the data are conveniently organized along three dimensions *time, x, y*.\n",
    "\n",
    "### Coordinates and Solar Zenith Angles\n",
    "Make a few more improvements to the structure of the dataset:\n",
    "* Add two-dimensional arrays (2) of lat and lon values to improve spatial metadata\n",
    "* Assign some additional metadata about the quality flags information to the *Mandatory_Quality* variables\n",
    "* etc.\n",
    "\n",
    "We need latitudes and longitudes to calculate the solar zenith angle, so use `numpy` and `proj` libraries to generate arrays of lat,lon equivalents for the *x, y* coordinates in the dataset. A few steps are required:\n",
    "\n",
    "#### Define SRS\n",
    "Define spatial information for the source x,y arrays and the target lon,lat arrays using `pyproj.Proj`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not aware of any geoscience application where sinusoidal coordinates are reference to an origin other than lat==0, lon==0. So, this piece is unnecessary, but it stays for the sake of provenance.\n",
    "\n",
    "I only used the lambda `getpar` to avoid having too many columns. The mess below is assembling the attributes from `ds.crs` into the proj4 string to be consumed by `pyproj.Proj`. Use the EPSG code for WGS84:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getpar = lambda a: str(ds.crs.attrs[a])\n",
    "\n",
    "inproj = Proj(\" \".join([\n",
    "    \"+proj=sinu\",\n",
    "    \"+lon_0=\"+getpar(\"longitude_of_central_meridian\"),\n",
    "    \"+x_0=\"+getpar(\"false_easting\"),\n",
    "    \"+y_0=\"+getpar(\"false_northing\"),\n",
    "    \"+a=\"+getpar(\"semi_major_axis\"),\n",
    "    \"+b=\"+getpar(\"semi_minor_axis\"),\n",
    "    \"+units=\"+\"meter +no_defs\"]))\n",
    "\n",
    "outproj = Proj(init=\"epsg:4326\")\n",
    "\n",
    "inproj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permute x and y\n",
    "After we expand **x** and **y** to two dimensions, we need immediately flatten them so when they're taken together they represent a sequence of latitude longitude pairs that enumerate over all pixels from top-left to bottom-right of the dataset. \n",
    "\n",
    "You can do this with `numpy.meshgrid` then `numpy.array.flatten`. Use `numpy.meshgrid` first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(ds.x.data, ds.y.data)\n",
    "\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flatten and transform\n",
    "Flatten and transform the expanded 2d arrays and pass them as arguments 3 and 4 to `pyproj.transform` to get lon,lat pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon1d, lat1d = transform(\n",
    "    inproj, \n",
    "    outproj, \n",
    "    xx.flatten(), \n",
    "    yy.flatten())\n",
    "\n",
    "print(\"First five (lon,lat) pairs:\"); list(zip(lon1d[:5], lat1d[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the new lon,lat arrays to match the original shape of the 2d x (`xx`) and y (`yy`) arrays. The **latitude** and **longitude** variables in the final dataset will be arranged along the **x** and **y** dimensions (both are 1d), so that every sinusoidal pixel is assigned a geographic reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon2d, lat2d = lon1d.reshape(xx.shape), lat1d.reshape(yy.shape)\n",
    "\n",
    "lat2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can add them to our dataset add two additional coordinate variables by creating an `xr.DataArray` for each and adding them to the dataset. This gets us closer to full compliance with CF recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords[\"lat\"] = xr.DataArray(\n",
    "    data=lat2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=dict(\n",
    "        standard_name=\"latitude\",\n",
    "        long_name=\"latitude coordinate\",\n",
    "        units=\"degrees_north\"))\n",
    "\n",
    "ds.coords[\"lon\"] = xr.DataArray(\n",
    "    data=lon2d, \n",
    "    coords=[ds.y, ds.x], \n",
    "    dims=[\"y\", \"x\"], \n",
    "    attrs=dict(\n",
    "        standard_name=\"longitude\",\n",
    "        long_name=\"longitude coordinate\",\n",
    "        units=\"degrees_east\"))\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SZN\n",
    "The only input to black- and white-sky albedos that doesn't come in MCD43A1 is the solar zenith angle (but, you can get it in MCD43A2 if you wish to use local solar noon). \n",
    "\n",
    "`*needs explanation*`\n",
    "\n",
    "In this next cell, we import define the function that is implemented in [the first notebook](0_Terms_and_concepts.ipynb) and test it for the first pixel in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_solar_zenith(doy, latitude, ndoy=365):\n",
    "    \"\"\" \"\"\"\n",
    "    declination = cos(radians((doy+10)*(360/ndoy)))*-23.45\n",
    "    altitude = 90 - latitude + declination\n",
    "    zenith = 90 - altitude\n",
    "    return(zenith)\n",
    "\n",
    "\n",
    "sza = get_solar_zenith(ds.time[0].dt.dayofyear, ds.lat[0][0])\n",
    "sza.name = \"solar_zenith_angle\"\n",
    "\n",
    "sza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also write a simple function to vectorize each calculation over our giant array. It should run significantly faster than a for loop. We can only vectorize over coordinates with matching dimensions, so we will have to loop over the timesteps.\n",
    "\n",
    "```python\n",
    "def vectorized(a, b):\n",
    "    func = lambda x, y: np.sqrt(x ** 2 + y ** 2)\n",
    "    return xr.apply_ufunc(func, a, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sza_eval(doy, lat):\n",
    "    \"\"\"Convert CF to Python datetime.\"\"\"\n",
    "    func = lambda l: get_solar_zenith(doy, l)\n",
    "    return(xr.apply_ufunc(func, lat))\n",
    "    \n",
    "# evaluate sza over all arrays using list comprehension \n",
    "sza_arr = np.dstack([sza_eval(t.dt.dayofyear, ds.lat) for t in ds.time])\n",
    "sza_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an `xarray.DataArray` for the solar zenith angles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sza = xr.DataArray(\n",
    "    data=sza_arr, \n",
    "    coords=[ds.y, ds.x, ds.time],\n",
    "    dims=[\"y\", \"x\", \"time\"],\n",
    "    attrs=dict(\n",
    "        units=\"degree\",\n",
    "        standard_name=\"solar zenith angle\",\n",
    "        long_name=\"solar zenith angle\"))\n",
    "\n",
    "sza = sza.transpose(\"time\", \"y\", \"x\")\n",
    "sza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality flags\n",
    "We may decide to filter the pixels derived via magnitude BRDF inversions, but for now we will keep all data. They are already weighted to amplify the best observation over a 16 day period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Albedo\n",
    "\n",
    "Now we can calculate the albedos. \n",
    "\n",
    "Three model parameters representing fiso, fvol, fgeo for the RossThickLiSparseReciprocal BRDF model that are computed for bands 1-7 and three broad bands: nir, shortwave, and vis.\n",
    "\n",
    "MCD43A1 layers are named like:\n",
    "```shell\n",
    "\n",
    "BRDF_Albedo_Parameters-<BAND> ; BAND\n",
    "    Band1, \n",
    "    Band2, \n",
    "    Band3, \n",
    "    Band4, \n",
    "    Band5, \n",
    "    Band6, \n",
    "    Band7, \n",
    "    nir, \n",
    "    shortwave, \n",
    "    vis\n",
    "```\n",
    "\n",
    "#### Black sky albedo\n",
    "\n",
    "See [0_Introduction.ipynb#Black-sky-albedo](0_Introduction.ipynb#Black-sky-albedo) for more information. The black sky albedo polynomial is computed as:\n",
    "\n",
    "```shell   \n",
    "                          K=iso       k=vol           k=geo\n",
    "    G_0k(term 1)           1.0      -0.007574       -1.284909  \n",
    "    G_1k(term SZN^2)       0.0      -0.070987       -0.166314  \n",
    "    G_2k(term SZN^3)       0.0       0.307588        0.041840   \n",
    "    \n",
    "    BSA(SZN,BAND)=\n",
    "        F_iso(BAND)*(G_0iso + G_1iso*SZN^2 + G_2iso*SZN^3) +\n",
    "        F_vol(BAND)*(G_0vol + G_1vol*SZN^2 + G_2vol*SZN^3) +\n",
    "        F_geo(BAND)*(G_0geo + G_1geo*SZN^2 + G_2geo*SNZ^3)\n",
    "\n",
    "    SZN:  solar zenith angle\n",
    "    BAND: band wavelength\n",
    "    OD:   optical depth\n",
    "    AMT:  aerosol model type\n",
    "   \n",
    "```\n",
    "Define some functions that do the math above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fBSA(param1, param2, param3, sza):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    s = np.radians(sza)\n",
    "    func = lambda p1, p2, p3: (\n",
    "        p1*( 1.0      +  0.0     *(s**2) + 0.0     *(s**3)) +  # Isotropic\n",
    "        p2*(-0.007574 + -0.070987*(s**2) + 0.307588*(s**3)) +  # RossThick\n",
    "        p3*(-1.284909 + -0.166314*(s**2) + 0.041840*(s**3)))   # LiSparseR\n",
    "    \n",
    "    return(xr.apply_ufunc(func, param1, param2, param3))\n",
    "\n",
    "\n",
    "b1 = ds[\"BRDF_Albedo_Parameters_nir\"]\n",
    "param1 = b1.sel(param=0)\n",
    "param2 = b1.sel(param=1)\n",
    "param3 = b1.sel(param=2)\n",
    "bsa = fBSA(param1, param2, param3, sza)\n",
    "\n",
    "bsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add attributes to the black sky albedo array and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsa.name = \"Black_sky_albedo\"\n",
    "bsa.attrs = dict(\n",
    "    _FillValue=32767,\n",
    "    coordinates=\"time y x\",\n",
    "    grid_mapping=\"crs\",\n",
    "    valid_min=0,\n",
    "    valid_max=32766,\n",
    "    long_name=\"Black_sky_albedo\",\n",
    "    units=\"reflectance, no units\",\n",
    "    scale_factor_err=0.0,\n",
    "    add_offset_err=0.0,\n",
    "    calibrated_nt=5,\n",
    "    scale_factor=0.001,\n",
    "    add_offset=0.0)\n",
    "\n",
    "bsa[0].plot.pcolormesh(x='x', y='y', robust=True, figsize=(10, 9),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### White sky albedo\n",
    "\n",
    "See [0_Introduction.ipynb#White-sky-albedo](0_Introduction.ipynb#White-sky-albedo) for more information. The black sky albedo polynomial is computed as:\n",
    "\n",
    "```shell\n",
    "              K=iso       k=vol           k=geo\n",
    "    WSA       1.0       0.189184       -1.377622\n",
    " \n",
    "    WSA(SZN,BAND)=\n",
    "        F_iso(BAND)* 1.0      +\n",
    "        F_vol(BAND)* 0.189184 +\n",
    "        F_geo(BAND)*-1.377622\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fWSA(param1, param2, param3):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    func = lambda p1, p2, p3: (\n",
    "        p1* 1.0       +           # Isotropic\n",
    "        p2* 0.189184  +           # RossThick\n",
    "        p3*-1.377622 )            # LiSparseR  \n",
    "    \n",
    "    return(xr.apply_ufunc(func, param1, param2, param3))\n",
    "\n",
    "\n",
    "wsa = fWSA(param1, param2, param3)\n",
    "wsa.name = \"White_sky_albedo\"\n",
    "wsa.attrs = dict(\n",
    "    _FillValue=32767,\n",
    "    coordinates=\"time y x\",\n",
    "    grid_mapping=\"crs\",\n",
    "    valid_min=0,\n",
    "    valid_max=32766,\n",
    "    long_name=\"White_sky_albedo\",\n",
    "    units=\"reflectance, no units\",\n",
    "    scale_factor_err=0.0,\n",
    "    add_offset_err=0.0,\n",
    "    calibrated_nt=5,\n",
    "    scale_factor=0.001,\n",
    "    add_offset=0.0)\n",
    "\n",
    "wsa[0].plot.pcolormesh(x='x', y='y', robust=True, figsize=(10, 9),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blue sky albedo \n",
    "\n",
    "The lookup values for each band are stored in tables in a text file at: */proc/actual_albedo_tool/albedo/skyl_lut.dat*. The values in the twenty tables are arranged such that the optical depth input (two-decimal places) selects the column and solar zenith angle input selects the row of the appropriate value. \n",
    "\n",
    "I cleaned up the table a little bit to make it easier to parse with `pandas`. The new file is at: [proc/skyl_lut.dat](proc/skyl_lut.dat).\n",
    "\n",
    "Open the text file, parse it to a dictionary of tables numbered by band, and make a lookup function that returns the appropriate value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/skyl_lut.dat\", \"r\") as f:\n",
    "    tab = f.read().replace(\"  \", \" \")\n",
    "\n",
    "con, mar = [t.split(\"Band\") for t in tab.split(\"Aerosol_type: \")[1:]]\n",
    "luts = {i+1: pd.read_csv(\n",
    "    StringIO(b),\n",
    "    index_col=\"S&O\",\n",
    "    skiprows=1,\n",
    "    sep=\" \") for i, b in enumerate(con[1:])}\n",
    "   \n",
    "\n",
    "def lookup(sza, luc):\n",
    "    \"\"\" \"\"\"    \n",
    "    lfunc = lambda s: luc.iloc[s].values\n",
    "    return(xr.apply_ufunc(lfunc, abs(sza).round(),))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optical depth `sod` can be adjusted `0.00 to 0.98`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sod = \"0.02\" # solar optical depth \n",
    "luv = lookup(sza.data.flatten(), luts[9][sod])\n",
    "lu = xr.DataArray(\n",
    "    data=luv.reshape(sza.shape), \n",
    "    coords=[sza.time, sza.y, sza.x],\n",
    "    dims=[\"time\", \"y\", \"x\"],\n",
    "    attrs=dict(\n",
    "        units=\"unitless\",\n",
    "        long_name=\"near-infrared lookup value\"))\n",
    "\n",
    "lu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, blue sky albedo is calculated by:\n",
    "```\n",
    "Blue_sky_albedo = White_sky_albedo*Lookup + Black_sky_albedo*(1-Lookup)\n",
    "```\n",
    "\n",
    "Make a vectorized function that applies that equation to all of the pixels of the arrays and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alb_vectorized(wsa, bsa, lookup):\n",
    "    \"\"\"Vectorize albedo polynomials over two 3d arrays.\"\"\"\n",
    "    afunc = lambda w,b,l: (w*l)+(b*(1-l))\n",
    "    return(xr.apply_ufunc(afunc, wsa, bsa, lookup))\n",
    "\n",
    "\n",
    "alb = alb_vectorized(wsa, bsa, lu)\n",
    "alb.name = \"Blue_sky_albedo\"\n",
    "alb.attrs = dict(\n",
    "    _FillValue=32767,\n",
    "    coordinates=\"time y x\",\n",
    "    grid_mapping=\"crs\",\n",
    "    valid_min=0,\n",
    "    valid_max=32766,\n",
    "    long_name=\"Blue_sky_albedo\",\n",
    "    units=\"reflectance, no units\",\n",
    "    scale_factor_err=0.0,\n",
    "    add_offset_err=0.0,\n",
    "    calibrated_nt=5,\n",
    "    scale_factor=0.001,\n",
    "    add_offset=0.0)\n",
    "\n",
    "alb.mean(\"time\").plot.pcolormesh(x='x', y='y', robust=True, figsize=(10, 9),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's how you calculate blue sky albedo. In the next notebook ([2_Batch_Process.ipynb](2_Batch_Process.ipynb)), define some functions that cover the steps above and calculate albedos for the remaining bands in a loop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
